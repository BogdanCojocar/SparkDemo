apply plugin: 'scala'

sourceCompatibility = 1.5
version = '1.0'
jar {
    manifest {
        attributes 'Implementation-Title': 'Spark Demo', 'Implementation-Version': version
    }
}

repositories {
    mavenCentral()
}

def spark_version = "1.1.0"
def scala_version = "2.10.4"
def scala_spark_version = "2.10"
def junit_version = "4.11"

dependencies {
    compile "org.scala-lang:scala-library:$scala_version"
    compile "org.scala-lang:scala-compiler:$scala_version"
    compile "org.apache.spark:spark-core_$scala_spark_version:$spark_version"
	compile 'org.apache.hadoop:hadoop-streaming:2.4.1'
	compile 'org.mongodb:mongo-java-driver:2.12.4'
	compile 'org.mongodb:mongo-hadoop-core:1.3.0'
	
	testCompile group: 'junit', name: 'junit', version: "$junit_version"
}

tasks.withType(ScalaCompile) {  
    scalaCompileOptions.additionalParameters = ['-target:jvm-1.7']  
}

task fatJar(type: Jar) {
	manifest {
        attributes 'Implementation-Title': 'Spark Demo using Gradle',  
        	'Implementation-Version': version,
        	'Main-Class': 'org.demo.spark.main.SparkDemo'
    }
    baseName = project.name + '-all'
    exclude 'META-INF/*.RSA', 'META-INF/*.SF','META-INF/*.DSA' 
    from { configurations.compile.collect { it.isDirectory() ? it : zipTree(it) } }
    with jar
}




